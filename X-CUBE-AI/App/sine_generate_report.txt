ST Edge AI Core v1.0.0-19894
Created date          : 2024-10-15 17:32:20
Parameters            : generate --target stm32l4 --name sine -m D:/raulc/MUICR/TFM/tensorflow/tensorflow/lite/experimental/micro/examples/hello_world/sine_model_quantized.tflite --compression none --verbosity 1 --allocate-inputs --allocate-outputs --workspace C:/Users/raulc/AppData/Local/Temp/mxAI_workspace41784252798340016528160025174183774 --output C:/Users/raulc/.stm32cubemx/sine_output

Exec/report summary (generate)
-------------------------------------------------------------------------------------------------------------------------------------------
model file         :   D:\raulc\MUICR\TFM\tensorflow\tensorflow\lite\experimental\micro\examples\hello_world\sine_model_quantized.tflite   
type               :   tflite                                                                                                              
c_name             :   sine                                                                                                                
compression        :   none                                                                                                                
options            :   allocate-inputs, allocate-outputs                                                                                   
optimization       :   balanced                                                                                                            
target/series      :   stm32l4                                                                                                             
workspace dir      :   C:\Users\raulc\AppData\Local\Temp\mxAI_workspace41784252798340016528160025174183774                                 
output dir         :   C:\Users\raulc\.stm32cubemx\sine_output                                                                             
model_fmt          :   ss/sa per channel                                                                                                   
model_name         :   sine_model_quantized                                                                                                
model_hash         :   0x0d869c09bb2e39e9f3c535a811cbf775                                                                                  
params #           :   321 items (420 B)                                                                                                   
-------------------------------------------------------------------------------------------------------------------------------------------
input 1/1          :   'serving_default_keras_tensor_40', f32(1x1), 4 Bytes, activations                                                   
output 1/1         :   'conversion_4', f32(1x1), 4 Bytes, activations                                                                      
macc               :   325                                                                                                                 
weights (ro)       :   420 B (420 B) (1 segment) / -864(-67.3%) vs float model                                                             
activations (rw)   :   224 B (224 B) (1 segment) *                                                                                         
ram (total)        :   224 B (224 B) = 224 + 0 + 0                                                                                         
-------------------------------------------------------------------------------------------------------------------------------------------
(*) 'input'/'output' buffers can be used from the activations buffer

Model name - sine_model_quantized
------ ------------------------------------------- ------------- ------------ ------ --------------------------------- --- -------------- --------------- ------------------- 
m_id   layer (type,original)                       oshape        param/size     macc                      connected to   | c_size         c_macc          c_type              
------ ------------------------------------------- ------------- ------------ ------ --------------------------------- --- -------------- --------------- ------------------- 
0      serving_default_keras_tensor_40 (Input, )   [b:1,c:1]                                                             |                +2(+100.0%)     Conversion_[0]      
       conversion_0 (Conversion, QUANTIZE)         [b:1,c:1]                       2   serving_default_keras_tensor_40   |                -2(-100.0%)     
------ ------------------------------------------- ------------- ------------ ------ --------------------------------- --- -------------- --------------- ------------------- 
1      tfl_pseudo_qconst5 (Placeholder, )          [h:16,c:1]    16/16                                                   | +64(+400.0%)   +32(+100.0%)    Dense_[1]           
       tfl_pseudo_qconst4 (Placeholder, )          [c:16]        16/64                                                   | -64(-100.0%)                   
       gemm_1 (Gemm, FULLY_CONNECTED)              [b:1,c:16]                     32                      conversion_0   |                -32(-100.0%)    
                                                                                                    tfl_pseudo_qconst5   | 
                                                                                                    tfl_pseudo_qconst4   | 
       nl_1_nl (Nonlinearity, FULLY_CONNECTED)     [b:1,c:16]                     16                            gemm_1   |                -16(-100.0%)    
------ ------------------------------------------- ------------- ------------ ------ --------------------------------- --- -------------- --------------- ------------------- 
2      tfl_pseudo_qconst3 (Placeholder, )          [h:16,c:16]   256/256                                                 | +64(+25.0%)    +272(+100.0%)   Dense_[2]           
       tfl_pseudo_qconst2 (Placeholder, )          [c:16]        16/64                                                   | -64(-100.0%)                   
       gemm_2 (Gemm, FULLY_CONNECTED)              [b:1,c:16]                    272                           nl_1_nl   |                -272(-100.0%)   
                                                                                                    tfl_pseudo_qconst3   | 
                                                                                                    tfl_pseudo_qconst2   | 
       nl_2_nl (Nonlinearity, FULLY_CONNECTED)     [b:1,c:16]                     16                            gemm_2   |                -16(-100.0%)    
------ ------------------------------------------- ------------- ------------ ------ --------------------------------- --- -------------- --------------- ------------------- 
3      tfl_pseudo_qconst1 (Placeholder, )          [b:1,c:16]    16/16                                                   | +4(+25.0%)     +17(+100.0%)    Dense_[3]           
       tfl_pseudo_qconst (Placeholder, )           [c:1]         1/4                                                     | -4(-100.0%)                    
       gemm_3 (Gemm, FULLY_CONNECTED)              [b:1,c:1]                      17                           nl_2_nl   |                -17(-100.0%)    
                                                                                                    tfl_pseudo_qconst1   | 
                                                                                                     tfl_pseudo_qconst   | 
------ ------------------------------------------- ------------- ------------ ------ --------------------------------- --- -------------- --------------- ------------------- 
4      conversion_4 (Conversion, DEQUANTIZE)       [b:1,c:1]                       2                            gemm_3   |                                Conversion_[o][4]   
------ ------------------------------------------- ------------- ------------ ------ --------------------------------- --- -------------- --------------- ------------------- 
model/c-model: macc=357/325 -32(-9.0%) weights=420/420  activations=--/224 io=--/0



Generated C-graph summary
------------------------------------------------------------------------------------------------------------------------
model name            : sine_model_quantized
c-name                : sine
c-node #              : 5
c-array #             : 15
activations size      : 224 (1 segment)
weights size          : 420 (1 segment)
macc                  : 325
inputs                : ['serving_default_keras_tensor_40_output']
outputs               : ['conversion_4_output']

C-Arrays (15)
------ ---------------------------------------- ----------- ------------------------- ----------- --------- 
c_id   name (*_array)                           item/size   domain/mem-pool           c-type      comment   
------ ---------------------------------------- ----------- ------------------------- ----------- --------- 
0      conversion_0_output                      1/1         activations/**default**   s8                    
1      conversion_4_output                      1/4         activations/**default**   float       /output   
2      gemm_1_bias                              16/64       weights/weights           const s32             
3      gemm_1_output                            16/16       activations/**default**   s8                    
4      gemm_1_scratch0                          81/162      activations/**default**   s16                   
5      gemm_1_weights                           16/16       weights/weights           const s8              
6      gemm_2_bias                              16/64       weights/weights           const s32             
7      gemm_2_output                            16/16       activations/**default**   s8                    
8      gemm_2_scratch0                          96/192      activations/**default**   s16                   
9      gemm_2_weights                           256/256     weights/weights           const s8              
10     gemm_3_bias                              1/4         weights/weights           const s32             
11     gemm_3_output                            1/1         activations/**default**   s8                    
12     gemm_3_scratch0                          16/32       activations/**default**   s16                   
13     gemm_3_weights                           16/16       weights/weights           const s8              
14     serving_default_keras_tensor_40_output   1/4         activations/**default**   float       /input    
------ ---------------------------------------- ----------- ------------------------- ----------- --------- 

C-Layers (5)
------ ---------------- ---- ------------- ------ ----- ------------------------------------------- ------------------ 
c_id   name (*_layer)   id   layer_type    macc   rom   tensors                                     shape (array id)   
------ ---------------- ---- ------------- ------ ----- ------------------------------------------- ------------------ 
0      conversion_0     0    Conversion    2      0     I: serving_default_keras_tensor_40_output   f32(1x1) (14)      
                                                        O: conversion_0_output                      int8(1x1) (0)      
------ ---------------- ---- ------------- ------ ----- ------------------------------------------- ------------------ 
1      gemm_1           1    Dense         32     80    I: conversion_0_output                      int8(1x1) (0)      
                                                        S: gemm_1_scratch0                                             
                                                        W: gemm_1_weights                           int8(16x1) (5)     
                                                        W: gemm_1_bias                              int32(16) (2)      
                                                        O: gemm_1_output                            int8(1x16) (3)     
------ ---------------- ---- ------------- ------ ----- ------------------------------------------- ------------------ 
2      gemm_2           2    Dense         272    320   I: gemm_1_output                            int8(1x16) (3)     
                                                        S: gemm_2_scratch0                                             
                                                        W: gemm_2_weights                           int8(16x16) (9)    
                                                        W: gemm_2_bias                              int32(16) (6)      
                                                        O: gemm_2_output                            int8(1x16) (7)     
------ ---------------- ---- ------------- ------ ----- ------------------------------------------- ------------------ 
3      gemm_3           3    Dense         17     20    I: gemm_2_output                            int8(1x16) (7)     
                                                        S: gemm_3_scratch0                                             
                                                        W: gemm_3_weights                           int8(1x16) (13)    
                                                        W: gemm_3_bias                              int32(1) (10)      
                                                        O: gemm_3_output                            int8(1x1) (11)     
------ ---------------- ---- ------------- ------ ----- ------------------------------------------- ------------------ 
4      conversion_4     4    Conversion    2      0     I: gemm_3_output                            int8(1x1) (11)     
                                                        O: conversion_4_output                      f32(1x1) (1)       
------ ---------------- ---- ------------- ------ ----- ------------------------------------------- ------------------ 



Number of operations per c-layer
------- ------ --------------------------- ----- ------------- 
c_id    m_id   name (type)                   #op          type 
------- ------ --------------------------- ----- ------------- 
0       0      conversion_0 (Conversion)       2   smul_f32_s8 
1       1      gemm_1 (Dense)                 32    smul_s8_s8 
2       2      gemm_2 (Dense)                272    smul_s8_s8 
3       3      gemm_3 (Dense)                 17    smul_s8_s8 
4       4      conversion_4 (Conversion)       2   smul_s8_f32 
------- ------ --------------------------- ----- ------------- 
total                                        325 

Number of operation types
---------------- ----- ----------- 
operation type       #           % 
---------------- ----- ----------- 
smul_f32_s8          2        0.6% 
smul_s8_s8         321       98.8% 
smul_s8_f32          2        0.6% 

Complexity report (model)
------ --------------------------------- ------------------------- ------------------------- ------ 
m_id   name                              c_macc                    c_rom                     c_id   
------ --------------------------------- ------------------------- ------------------------- ------ 
0      serving_default_keras_tensor_40   |                  0.6%   |                  0.0%   [0]    
1      tfl_pseudo_qconst5                ||                 9.8%   ||||              19.0%   [1]    
2      tfl_pseudo_qconst3                ||||||||||||||||  83.7%   ||||||||||||||||  76.2%   [2]    
3      tfl_pseudo_qconst1                |                  5.2%   |                  4.8%   [3]    
4      conversion_4                      |                  0.6%   |                  0.0%   [4]    
------ --------------------------------- ------------------------- ------------------------- ------ 
macc=325 weights=420 act=224 ram_io=0

Generated files (7)
------------------------------------------------------------ 
C:\Users\raulc\.stm32cubemx\sine_output\sine_data_params.h   
C:\Users\raulc\.stm32cubemx\sine_output\sine_data_params.c   
C:\Users\raulc\.stm32cubemx\sine_output\sine_data.h          
C:\Users\raulc\.stm32cubemx\sine_output\sine_data.c          
C:\Users\raulc\.stm32cubemx\sine_output\sine_config.h        
C:\Users\raulc\.stm32cubemx\sine_output\sine.h               
C:\Users\raulc\.stm32cubemx\sine_output\sine.c               
